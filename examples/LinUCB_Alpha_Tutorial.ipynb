{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cff07d9",
   "metadata": {},
   "source": [
    "# LinUCB Alpha Sweep Tutorial\n",
    "This notebook walks through preparing the MovieLens-100K-based simulator in EasyRL4Rec, running LinUCB with multiple exploration coefficients (`alpha`), and visualizing how the metric changes.\n",
    "It mirrors the automation we scripted, but keeps everything reproducible for other users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574f2c83",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "1. Download MovieLens-100K (e.g., `curl -LO https://files.grouplens.org/datasets/movielens/ml-100k.zip`).\n",
    "2. Extract into `data/MovieLens/data_raw/`:\n",
    "   ```bash\n",
    "   mkdir -p data/MovieLens/data_raw\n",
    "   unzip ml-100k.zip -d data/MovieLens/data_raw/\n",
    "   ```\n",
    "3. Install repo dependencies (`conda create`, `sh install.sh`, clone tianshou`).\n",
    "4. Activate the conda env (`conda activate easyrl4rec`).\n",
    "5. Run the cells below to convert the raw files, split train/test, and generate the MF simulator.\n",
    "GPU is optional; CPU is fine for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da277607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT = Path('..').resolve()  # notebook sits in examples/\n",
    "print('Project root:', ROOT)\n",
    "def run_cmd(args):\n",
    "    print('\\n$',' '.join(str(a) for a in args))\n",
    "    subprocess.run(args, check=True, cwd=ROOT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c078e7",
   "metadata": {},
   "source": [
    "## Step 1 – Prepare the MovieLens simulator data\n",
    "These cells convert the ML-100K raw files into the format EasyRL4Rec expects, split train/test logs, and generate the matrix-factorization rating matrix the simulator uses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e571cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cmd([sys.executable, 'script/convert_100k.py'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c8b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_cmd([sys.executable, 'data/MovieLens/split_train_test.py'])\n",
    "run_cmd([sys.executable, 'data/MovieLens/provide_MF_results.py'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35ebd5a",
   "metadata": {},
   "source": [
    "### What do these preprocessing scripts do?\n",
    "- `script/convert_100k.py`: converts the original ML-100K raw files (`u.data`, `u.user`, `u.item`) into the format expected inside EasyRL4Rec (double-colon separated `ratings.dat`, `users.dat`, `movies.dat`). See lines 5–43 for the transformations, including mapping occupations to ints and embedding release years into the title.\n",
    "- `data/MovieLens/split_train_test.py`: splits `ratings.dat` into `movielens-1m-train.csv`/`movielens-1m-test.csv` (90/10 chronological split); this is what `MovieLensData.get_train_data()` reads (lines 1–60).\n",
    "- `data/MovieLens/provide_MF_results.py`: trains a simple MF model (lines 16–132) to predict missing entries in the user–item matrix and saves the dense `rating_matrix.csv` that powers the simulator; see the `MatrixFactorization` definition (lines 40–108)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a58b243",
   "metadata": {},
   "source": [
    "## Step 2 – Sweep LinUCB alpha values\n",
    "We reuse `script/sweep_linucb_alpha.py` to run LinUCB with several `alpha` values.\n",
    "Use `--extra-args` to pass flags to `run_LinUCB.py` (here we force `--num_workers 0` because macOS blocks shared memory)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5961dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = ['0.1','0.5','1.0','2.0','5.0']\n",
    "cmd = [\n",
    "    sys.executable, 'script/sweep_linucb_alpha.py',\n",
    "    '--message-prefix', 'notebook',\n",
    "    '--plot-path', 'visual_results/linucb_alpha_comparison.png',\n",
    "    '--results-json', 'visual_results/linucb_alpha_results.json',\n",
    "    '--alphas', *alphas,\n",
    "    '--extra-args', '--num_workers', '0'\n",
    "]\n",
    "run_cmd(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da02b67d",
   "metadata": {},
   "source": [
    "## Step 3 – Inspect the aggregated metrics\n",
    "The sweep script saves metrics and a plot under `visual_results/`. Let's load and visualize them inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7d54f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = ROOT / 'visual_results' / 'linucb_alpha_results.json'\n",
    "with open(results_path) as f:\n",
    "    metrics = json.load(f)\n",
    "df = pd.DataFrame(metrics).T.astype(float).sort_index(key=lambda s: s.astype(float))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2f80a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12,4))\n",
    "df.sort_index().plot(y='ctr', marker='o', ax=axes[0])\n",
    "axes[0].set_title('CTR vs alpha')\n",
    "axes[0].set_ylabel('Average reward (ctr)')\n",
    "df.sort_index().plot(y='click_loss', marker='o', color='C3', ax=axes[1])\n",
    "axes[1].set_title('Click loss vs alpha')\n",
    "axes[1].set_ylabel('Avg |prediction - reward|')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61640c9",
   "metadata": {},
   "source": [
    "## How the training script works\n",
    "`script/sweep_linucb_alpha.py` shells out to `examples/usermodel/run_LinUCB.py`. That runner:\n",
    "1. Parses base hyperparameters via `examples/usermodel/usermodel_utils.py` (lines 20–120).\n",
    "2. Calls `run_Egreedy.prepare_dataset` (lines 91–118) which uses `MovieLensData` to load and encode features.\n",
    "3. Builds the LinUCB user model through `run_Egreedy.setup_user_model`, which constructs `EnsembleModel` → `UserModel_Pairwise_Variance` (source: `src/core/userModel/user_model_ensemble.py`, `src/core/userModel/user_model_pairwise_variance.py`).\n",
    "4. Kicks off training and evaluation; online metrics are computed in `src/core/evaluation/evaluator_static.py` (see `test_static_model_in_RL_env`).\n",
    "These references are handy if you want to dive into the exact loss, state tracker, or evaluator logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12fda30",
   "metadata": {},
   "source": [
    "## Step 4 – Next steps\n",
    "- Adjust the alpha grid or pass `--extra-args --epoch 5` to train longer.\n",
    "- Use the saved logs (`saved_models/MovieLensEnv-v0/LinUCB/logs/[message]_*`) for deeper analysis.\n",
    "- Swap in other environments by changing `--env` inside the sweep script."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
